# Random-convolution-layer
## "Random convolution layer: An auxiliary method to improve fault diagnosis performance" has been accepted for publication in Journal of Intelligent Manufacturing
In real industry, it is often difficult to obtain large-scale labeled data. Existing Convolutional Neural Network (CNN)-based fault diagnosis methods often struggle to achieve accurate diagnoses of machine conditions due to the scarcity of labeled data, hindering the ability of models to develop strong inductive biases. We propose a plug-and-play auxiliary method, random convolution layer (RCL), to improve the generalization performance of the fault diagnosis models. This method delves into the fundamental commonalities across diverse tasks and varying network structures, thereby enhancing the diversity of samples to establish a more robust source domain environment. The RCL preserves the dimensional nature of the data in the time domain while randomly altering the kernel sizes during convolution operations, thus generating new data without compromising global information. During the training process, the newly generated data is mixed with the original data and fed into the fault diagnosis model. RCL is incorporated as a module into the inputs of different fault diagnosis models, and its effectiveness is validated on three public datasets as well as a self-built testbed. The results show that the present auxiliary method improves the domain generalization performance of the baselines, and can improve the accuracy of the corresponding fault diagnosis models. Our code is available at https://github.com/zhiqan/Random-convolution-layer.
## The method was validated using four datasets, and performance analysis was completed using 12 popular and diverse area of fault diagnosis baseline methods, as well as 24 diagnostic cases (high-noise diagnostic case, single-domain diagnostic case, and cross-domain diagnostic cases).
